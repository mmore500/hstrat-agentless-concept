{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapted from <https://developmentalsystems.org/sensorimotor-lenia/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numbers\n",
    "import warnings\n",
    "\n",
    "from addict import Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class VideoWriter:\n",
    "    def __init__(self, filename, fps=30.0, fourcc=\"mp4v\"):\n",
    "        self.filename = filename\n",
    "        self.fps = fps\n",
    "        self.writer = None\n",
    "        # Define the codec using OpenCV's VideoWriter_fourcc function.\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*fourcc)\n",
    "\n",
    "    def add(self, img):\n",
    "        img = np.asarray(img)\n",
    "        # Convert image from float to uint8 if needed.\n",
    "        if img.dtype in [np.float32, np.float64]:\n",
    "            img = np.uint8(np.clip(img, 0, 1) * 255)\n",
    "        # If the image is grayscale, convert it to a 3-channel BGR image.\n",
    "        if len(img.shape) == 2 or (len(img.shape) == 3 and img.shape[2] == 1):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        # Initialize the writer when the first frame is added.\n",
    "        if self.writer is None:\n",
    "            h, w = img.shape[:2]\n",
    "            self.writer = cv2.VideoWriter(\n",
    "                self.filename, self.fourcc, self.fps, (w, h)\n",
    "            )\n",
    "        self.writer.write(img)\n",
    "\n",
    "    def close(self):\n",
    "        if self.writer:\n",
    "            self.writer.release()\n",
    "            self.writer = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.close()\n",
    "\n",
    "    def show(self, width=640, height=480):\n",
    "        self.close()\n",
    "        # Display the saved video in the notebook.\n",
    "        print(\"bypassing output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_mult_torch(X, Y):\n",
    "    \"\"\"Computes the complex multiplication in Pytorch when the tensor last dimension is 2: 0 is the real component and 1 the imaginary one\"\"\"\n",
    "    assert X.shape[-1] == 2 and Y.shape[-1] == 2, \"Last dimension must be 2\"\n",
    "    return torch.stack(\n",
    "        (\n",
    "            X[..., 0] * Y[..., 0] - X[..., 1] * Y[..., 1],\n",
    "            X[..., 0] * Y[..., 1] + X[..., 1] * Y[..., 0],\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "\n",
    "def roll_n(X, axis, n):\n",
    "    \"\"\"Rolls a tensor with a shift n on the specified axis\"\"\"\n",
    "    f_idx = tuple(\n",
    "        slice(None, None, None) if i != axis else slice(0, n, None)\n",
    "        for i in range(X.dim())\n",
    "    )\n",
    "    b_idx = tuple(\n",
    "        slice(None, None, None) if i != axis else slice(n, None, None)\n",
    "        for i in range(X.dim())\n",
    "    )\n",
    "    front = X[f_idx]\n",
    "    back = X[b_idx]\n",
    "    return torch.cat([back, front], axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Space(object):\n",
    "    \"\"\"\n",
    "    Defines the init_space, genome_space and intervention_space of a system\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape=None, dtype=None):\n",
    "        self.shape = None if shape is None else tuple(shape)\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Randomly sample an element of this space.\n",
    "        Can be uniform or non-uniform sampling based on boundedness of space.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def mutate(self, x):\n",
    "        \"\"\"\n",
    "        Randomly mutate an element of this space.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def contains(self, x):\n",
    "        \"\"\"\n",
    "        Return boolean specifying if x is a valid\n",
    "        member of this space\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def clamp(self, x):\n",
    "        \"\"\"\n",
    "        Return a valid clamped value of x inside space's bounds\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __contains__(self, x):\n",
    "        return self.contains(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteSpace(Space):\n",
    "    r\"\"\"A discrete space in :math:`\\{ 0, 1, \\\\dots, n-1 \\}`.\n",
    "    /!\\ mutation is gaussian by default: please create custom space inheriting from discrete space for custom mutation functions\n",
    "\n",
    "    Example::\n",
    "\n",
    "        >>> DiscreteSpace(2)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, mutation_mean=0.0, mutation_std=1.0, indpb=1.0):\n",
    "        assert n >= 0\n",
    "        self.n = n\n",
    "\n",
    "        # mutation_mean: mean for the gaussian addition mutation\n",
    "        # mutation_std: std for the gaussian addition mutation\n",
    "        # indpb \u2013 independent probability for each attribute to be mutated.\n",
    "        self.mutation_mean = torch.as_tensor(\n",
    "            mutation_mean, dtype=torch.float64\n",
    "        )\n",
    "        self.mutation_std = torch.as_tensor(mutation_std, dtype=torch.float64)\n",
    "        self.indpb = torch.as_tensor(indpb, dtype=torch.float64)\n",
    "        super(DiscreteSpace, self).__init__((), torch.int64)\n",
    "\n",
    "    def sample(self):\n",
    "        return torch.randint(self.n, ())\n",
    "\n",
    "    def mutate(self, x):\n",
    "        mutate_mask = torch.rand(self.shape) < self.indpb\n",
    "        noise = torch.normal(self.mutation_mean, self.mutation_std, ())\n",
    "        x = x.type(torch.float64) + mutate_mask * noise\n",
    "        x = torch.floor(x).type(self.dtype)\n",
    "        if not self.contains(x):\n",
    "            return self.clamp(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def contains(self, x):\n",
    "        if isinstance(x, int):\n",
    "            as_int = x\n",
    "        elif not x.dtype.is_floating_point and (\n",
    "            x.shape == ()\n",
    "        ):  # integer or size 0\n",
    "            as_int = int(x)\n",
    "        else:\n",
    "            return False\n",
    "        return 0 <= as_int < self.n\n",
    "\n",
    "    def clamp(self, x):\n",
    "        x = torch.max(x, torch.as_tensor(0, dtype=self.dtype, device=x.device))\n",
    "        x = torch.min(\n",
    "            x, torch.as_tensor(self.n - 1, dtype=self.dtype, device=x.device)\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DiscreteSpace(%d)\" % self.n\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DiscreteSpace) and self.n == other.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxSpace(Space):\n",
    "    \"\"\"\n",
    "    A (possibly unbounded) box in R^n. Specifically, a Box represents the\n",
    "    Cartesian product of n closed intervals. Each interval has the form of one\n",
    "    of [a, b], (-oo, b], [a, oo), or (-oo, oo).\n",
    "\n",
    "    There are two common use cases:\n",
    "\n",
    "    * Identical bound for each dimension::\n",
    "        >>> BoxSpace(low=-1.0, high=2.0, shape=(3, 4), dtype=torch.float32)\n",
    "        Box(3, 4)\n",
    "\n",
    "    * Independent bound for each dimension::\n",
    "        >>> BoxSpace(low=torch.tensor([-1.0, -2.0]), high=torch.tensor([2.0, 4.0]), dtype=torch.float32)\n",
    "        Box(2,)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        low,\n",
    "        high,\n",
    "        shape=None,\n",
    "        dtype=torch.float32,\n",
    "        mutation_mean=0.0,\n",
    "        mutation_std=1.0,\n",
    "        indpb=1.0,\n",
    "    ):\n",
    "        assert dtype is not None, \"dtype must be explicitly provided. \"\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # determine shape if it isn't provided directly\n",
    "        if shape is not None:\n",
    "            shape = tuple(shape)\n",
    "            assert (\n",
    "                isinstance(low, numbers.Number) or low.shape == shape\n",
    "            ), \"low.shape doesn't match provided shape\"\n",
    "            assert (\n",
    "                isinstance(high, numbers.Number) or high.shape == shape\n",
    "            ), \"high.shape doesn't match provided shape\"\n",
    "        elif not isinstance(low, numbers.Number):\n",
    "            shape = low.shape\n",
    "            assert (\n",
    "                isinstance(high, numbers.Number) or high.shape == shape\n",
    "            ), \"high.shape doesn't match low.shape\"\n",
    "        elif not isinstance(high, numbers.Number):\n",
    "            shape = high.shape\n",
    "            assert (\n",
    "                isinstance(low, numbers.Number) or low.shape == shape\n",
    "            ), \"low.shape doesn't match high.shape\"\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"shape must be provided or inferred from the shapes of low or high\"\n",
    "            )\n",
    "\n",
    "        if isinstance(low, numbers.Number):\n",
    "            low = torch.full(shape, low, dtype=dtype)\n",
    "\n",
    "        if isinstance(high, numbers.Number):\n",
    "            high = torch.full(shape, high, dtype=dtype)\n",
    "\n",
    "        self.shape = shape\n",
    "        self.low = low.type(self.dtype)\n",
    "        self.high = high.type(self.dtype)\n",
    "\n",
    "        # Boolean arrays which indicate the interval type for each coordinate\n",
    "        self.bounded_below = ~torch.isneginf(self.low)\n",
    "        self.bounded_above = ~torch.isposinf(self.high)\n",
    "\n",
    "        # mutation_mean: mean for the gaussian addition mutation\n",
    "        # mutation_std: std for the gaussian addition mutation\n",
    "        # indpb \u2013 independent probability for each attribute to be mutated.\n",
    "        if isinstance(mutation_mean, numbers.Number):\n",
    "            mutation_mean = torch.full(\n",
    "                self.shape, mutation_mean, dtype=torch.float64\n",
    "            )\n",
    "        self.mutation_mean = torch.as_tensor(\n",
    "            mutation_mean, dtype=torch.float64\n",
    "        )\n",
    "        if isinstance(mutation_std, numbers.Number):\n",
    "            mutation_std = torch.full(\n",
    "                self.shape, mutation_std, dtype=torch.float64\n",
    "            )\n",
    "        self.mutation_std = torch.as_tensor(mutation_std, dtype=torch.float64)\n",
    "        if isinstance(indpb, numbers.Number):\n",
    "            indpb = torch.full(self.shape, indpb, dtype=torch.float64)\n",
    "        self.indpb = torch.as_tensor(indpb, dtype=torch.float64)\n",
    "\n",
    "        super(BoxSpace, self).__init__(self.shape, self.dtype)\n",
    "\n",
    "    def is_bounded(self, manner=\"both\"):\n",
    "        below = torch.all(self.bounded_below)\n",
    "        above = torch.all(self.bounded_above)\n",
    "        if manner == \"both\":\n",
    "            return below and above\n",
    "        elif manner == \"below\":\n",
    "            return below\n",
    "        elif manner == \"above\":\n",
    "            return above\n",
    "        else:\n",
    "            raise ValueError(\"manner is not in {'below', 'above', 'both'}\")\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Generates a single random sample inside of the Box.\n",
    "\n",
    "        In creating a sample of the box, each coordinate is sampled according to\n",
    "        the form of the interval:\n",
    "\n",
    "        * [a, b] : uniform distribution\n",
    "        * [a, oo) : shifted exponential distribution\n",
    "        * (-oo, b] : shifted negative exponential distribution\n",
    "        * (-oo, oo) : normal distribution\n",
    "        \"\"\"\n",
    "        high = (\n",
    "            self.high.type(torch.float64)\n",
    "            if self.dtype.is_floating_point\n",
    "            else self.high.type(torch.int64) + 1\n",
    "        )\n",
    "        sample = torch.empty(self.shape, dtype=torch.float64)\n",
    "\n",
    "        # Masking arrays which classify the coordinates according to interval\n",
    "        # type\n",
    "        unbounded = ~self.bounded_below & ~self.bounded_above\n",
    "        upp_bounded = ~self.bounded_below & self.bounded_above\n",
    "        low_bounded = self.bounded_below & ~self.bounded_above\n",
    "        bounded = self.bounded_below & self.bounded_above\n",
    "\n",
    "        # Vectorized sampling by interval type\n",
    "        sample[unbounded] = torch.randn(\n",
    "            unbounded[unbounded].shape, dtype=torch.float64\n",
    "        )\n",
    "\n",
    "        sample[low_bounded] = (\n",
    "            -torch.rand(low_bounded[low_bounded].shape, dtype=torch.float64)\n",
    "        ).exponential_() + self.low[low_bounded]\n",
    "\n",
    "        sample[upp_bounded] = (\n",
    "            self.high[upp_bounded]\n",
    "            - (\n",
    "                -torch.rand(\n",
    "                    upp_bounded[upp_bounded].shape, dtype=torch.float64\n",
    "                )\n",
    "            ).exponential_()\n",
    "        )\n",
    "\n",
    "        sample[bounded] = (self.low[bounded] - high[bounded]) * torch.rand(\n",
    "            bounded[bounded].shape, dtype=torch.float64\n",
    "        ) + high[bounded]\n",
    "\n",
    "        if not self.dtype.is_floating_point:  # integer\n",
    "            sample = torch.floor(sample)\n",
    "\n",
    "        return sample.type(self.dtype)\n",
    "\n",
    "    def mutate(self, x, mask=None):\n",
    "        if mask is None:\n",
    "            mask = torch.ones(x.shape).to(x.device)\n",
    "\n",
    "        mutate_mask = mask * (\n",
    "            (torch.rand(self.shape) < self.indpb).type(torch.float64)\n",
    "        ).to(x.device)\n",
    "        noise = torch.normal(self.mutation_mean, self.mutation_std).to(\n",
    "            x.device\n",
    "        )\n",
    "        x = x.type(torch.float64) + mutate_mask * noise\n",
    "        if not self.dtype.is_floating_point:  # integer\n",
    "            x = torch.floor(x)\n",
    "        x = x.type(self.dtype)\n",
    "        if not self.contains(x):\n",
    "            return self.clamp(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def contains(self, x):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)  # Promote list to array for contains check\n",
    "        return (\n",
    "            x.shape == self.shape\n",
    "            and torch.all(\n",
    "                x\n",
    "                >= torch.as_tensor(self.low, dtype=self.dtype, device=x.device)\n",
    "            )\n",
    "            and torch.all(\n",
    "                x\n",
    "                <= torch.as_tensor(\n",
    "                    self.high, dtype=self.dtype, device=x.device\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def clamp(self, x):\n",
    "        if self.is_bounded(manner=\"below\"):\n",
    "            x = torch.max(\n",
    "                x, torch.as_tensor(self.low, dtype=self.dtype, device=x.device)\n",
    "            )\n",
    "        if self.is_bounded(manner=\"above\"):\n",
    "            x = torch.min(\n",
    "                x,\n",
    "                torch.as_tensor(self.high, dtype=self.dtype, device=x.device),\n",
    "            )\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BoxSpace({}, {}, {}, {})\".format(\n",
    "            self.low.min(), self.high.max(), self.shape, self.dtype\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            isinstance(other, BoxSpace)\n",
    "            and (self.shape == other.shape)\n",
    "            and torch.allclose(self.low, other.low)\n",
    "            and torch.allclose(self.high, other.high)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictSpace(Space):\n",
    "    \"\"\"\n",
    "    A Dict dictionary of simpler spaces.\n",
    "\n",
    "    Example usage:\n",
    "    self.genome_space = spaces.DictSpace({\"position\": spaces.Discrete(2), \"velocity\": spaces.Discrete(3)})\n",
    "\n",
    "    Example usage [nested]:\n",
    "    self.nested_genome_space = spaces.DictSpace({\n",
    "        'sensors':  spaces.DictSpace({\n",
    "            'position': spaces.Box(low=-100, high=100, shape=(3,)),\n",
    "            'velocity': spaces.Box(low=-1, high=1, shape=(3,)),\n",
    "            'front_cam': spaces.Tuple((\n",
    "                spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
    "                spaces.Box(low=0, high=1, shape=(10, 10, 3))\n",
    "            )),\n",
    "            'rear_cam': spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
    "        }),\n",
    "        'ext_controller': spaces.MultiDiscrete((5, 2, 2)),\n",
    "        'inner_state':spaces.DictSpace({\n",
    "            'charge': spaces.Discrete(100),\n",
    "            'system_checks': spaces.MultiBinary(10),\n",
    "            'job_status': spaces.DictSpace({\n",
    "                'task': spaces.Discrete(5),\n",
    "                'progress': spaces.Box(low=0, high=100, shape=()),\n",
    "            })\n",
    "        })\n",
    "    })\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spaces=None, **spaces_kwargs):\n",
    "        assert (spaces is None) or (\n",
    "            not spaces_kwargs\n",
    "        ), \"Use either DictSpace(spaces=dict(...)) or DictSpace(foo=x, bar=z)\"\n",
    "        if spaces is None:\n",
    "            spaces = spaces_kwargs\n",
    "        if isinstance(spaces, list):\n",
    "            spaces = Dict(spaces)\n",
    "        self.spaces = spaces\n",
    "        for space in spaces.values():\n",
    "            assert isinstance(\n",
    "                space, Space\n",
    "            ), \"Values of the attrdict should be instances of gym.Space\"\n",
    "        Space.__init__(\n",
    "            self, None, None\n",
    "        )  # None for shape and dtype, since it'll require special handling\n",
    "\n",
    "    def sample(self):\n",
    "        return Dict([(k, space.sample()) for k, space in self.spaces.items()])\n",
    "\n",
    "    def mutate(self, x):\n",
    "        return Dict(\n",
    "            [(k, space.mutate(x[k])) for k, space in self.spaces.items()]\n",
    "        )\n",
    "\n",
    "    def contains(self, x):\n",
    "        if not isinstance(x, dict) or len(x) != len(self.spaces):\n",
    "            return False\n",
    "        for k, space in self.spaces.items():\n",
    "            if k not in x:\n",
    "                return False\n",
    "            if not space.contains(x[k]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def clamp(self, x):\n",
    "        return Dict(\n",
    "            [(k, space.clamp(x[k])) for k, space in self.spaces.items()]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.spaces[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for key in self.spaces:\n",
    "            yield key\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"DictSpace(\"\n",
    "            + \", \".join(\n",
    "                [str(k) + \":\" + str(s) for k, s in self.spaces.items()]\n",
    "            )\n",
    "            + \")\"\n",
    "        )\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DictSpace) and self.spaces == other.spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDiscreteSpace(Space):\n",
    "    \"\"\"\n",
    "    - The multi-discrete space consists of a series of discrete spaces with different number of possible instances in eachs\n",
    "    - Can be initialized as\n",
    "\n",
    "        MultiDiscreteSpace([ 5, 2, 2 ])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nvec, mutation_mean=0.0, mutation_std=1.0, indpb=1.0):\n",
    "        \"\"\"\n",
    "        nvec: vector of counts of each categorical variable\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            torch.tensor(nvec) > 0\n",
    "        ).all(), \"nvec (counts) have to be positive\"\n",
    "        self.nvec = torch.as_tensor(nvec, dtype=torch.int64)\n",
    "        self.mutation_std = mutation_std\n",
    "\n",
    "        # mutation_mean: mean for the gaussian addition mutation\n",
    "        # mutation_std: std for the gaussian addition mutation\n",
    "        # indpb \u2013 independent probability for each attribute to be mutated.\n",
    "        if isinstance(mutation_mean, numbers.Number):\n",
    "            mutation_mean = torch.full(\n",
    "                self.nvec.shape, mutation_mean, dtype=torch.float64\n",
    "            )\n",
    "        self.mutation_mean = torch.as_tensor(\n",
    "            mutation_mean, dtype=torch.float64\n",
    "        )\n",
    "        if isinstance(mutation_std, numbers.Number):\n",
    "            mutation_std = torch.full(\n",
    "                self.nvec.shape, mutation_std, dtype=torch.float64\n",
    "            )\n",
    "        self.mutation_std = torch.as_tensor(mutation_std, dtype=torch.float64)\n",
    "        if isinstance(indpb, numbers.Number):\n",
    "            indpb = torch.full(self.nvec.shape, indpb, dtype=torch.float64)\n",
    "        self.indpb = torch.as_tensor(indpb, dtype=torch.float64)\n",
    "\n",
    "        super(MultiDiscreteSpace, self).__init__(self.nvec.shape, torch.int64)\n",
    "\n",
    "    def sample(self):\n",
    "        return (torch.rand(self.nvec.shape) * self.nvec).type(self.dtype)\n",
    "\n",
    "    def mutate(self, x):\n",
    "        mutate_mask = (torch.rand(self.shape) < self.indpb).to(x.device)\n",
    "        noise = torch.normal(self.mutation_mean, self.mutation_std).to(\n",
    "            x.device\n",
    "        )\n",
    "        x = x.type(torch.float64) + mutate_mask * noise\n",
    "        x = torch.floor(x).type(self.dtype)\n",
    "        if not self.contains(x):\n",
    "            return self.clamp(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def contains(self, x):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)  # Promote list to array for contains check\n",
    "        # if nvec is uint32 and space dtype is uint32, then 0 <= x < self.nvec guarantees that x\n",
    "        # is within correct bounds for space dtype (even though x does not have to be unsigned)\n",
    "        return (\n",
    "            x.shape == self.shape and (0 <= x).all() and (x < self.nvec).all()\n",
    "        )\n",
    "\n",
    "    def clamp(self, x):\n",
    "        x = torch.max(x, torch.as_tensor(0, dtype=self.dtype, device=x.device))\n",
    "        x = torch.min(\n",
    "            x,\n",
    "            torch.as_tensor(self.nvec - 1, dtype=self.dtype, device=x.device),\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"MultiDiscreteSpace({})\".format(self.nvec)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, MultiDiscreteSpace) and torch.all(\n",
    "            self.nvec == other.nvec\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxGoalSpace(BoxSpace):\n",
    "    def __init__(\n",
    "        self,\n",
    "        representation,\n",
    "        autoexpand=True,\n",
    "        low=0.0,\n",
    "        high=0.0,\n",
    "        shape=None,\n",
    "        dtype=torch.float32,\n",
    "    ):\n",
    "        self.representation = representation\n",
    "        self.autoexpand = autoexpand\n",
    "        if shape is not None:\n",
    "            if isinstance(shape, list) or isinstance(shape, tuple):\n",
    "                assert (\n",
    "                    len(shape) == 1\n",
    "                    and shape[0] == self.representation.n_latents\n",
    "                )\n",
    "            elif isinstance(shape, numbers.Number):\n",
    "                assert shape == self.representation.n_latents\n",
    "        BoxSpace.__init__(\n",
    "            self,\n",
    "            low=low,\n",
    "            high=high,\n",
    "            shape=(self.representation.n_latents,),\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "    def map(self, observations, **kwargs):\n",
    "        embedding = self.representation.calc(observations, **kwargs)\n",
    "        if self.autoexpand:\n",
    "            embedding_c = embedding.detach()\n",
    "            is_nan_mask = torch.isnan(embedding_c)\n",
    "            if is_nan_mask.sum() > 0:\n",
    "                embedding_c[is_nan_mask] = self.low[is_nan_mask]\n",
    "                self.low = torch.min(self.low, embedding_c)\n",
    "                embedding_c[is_nan_mask] = self.high[is_nan_mask]\n",
    "                self.high = torch.max(self.high, embedding_c)\n",
    "            else:\n",
    "                self.low = torch.min(self.low, embedding_c)\n",
    "                self.high = torch.max(self.high, embedding_c)\n",
    "        return embedding\n",
    "\n",
    "    def calc_distance(self, embedding_a, embedding_b, **kwargs):\n",
    "        return self.representation.calc_distance(\n",
    "            embedding_a, embedding_b, **kwargs\n",
    "        )\n",
    "\n",
    "    def sample(self):\n",
    "        return BoxSpace.sample(self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeniaInitializationSpace(DictSpace):\n",
    "    \"\"\"Class for initialization space that allows to sample and clip the initialization\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        default_config.neat_config = None\n",
    "        default_config.cppn_n_passes = 2\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, init_size=40, config={}, **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "        spaces = Dict(\n",
    "            # cppn_genome = LeniaCPPNInitSpace(self.config)\n",
    "            init=BoxSpace(\n",
    "                low=0.0,\n",
    "                high=1.0,\n",
    "                shape=(init_size, init_size),\n",
    "                mutation_mean=torch.zeros((40, 40)),\n",
    "                mutation_std=torch.ones((40, 40)) * 0.01,\n",
    "                indpb=0.0,\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        DictSpace.__init__(self, spaces=spaces)\n",
    "\n",
    "\n",
    "\"\"\" =============================================================================================\n",
    "Lenia Update Rule Space:\n",
    "============================================================================================= \"\"\"\n",
    "\n",
    "\n",
    "class LeniaUpdateRuleSpace(DictSpace):\n",
    "    \"\"\"Space associated to the parameters of the update rule\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, nb_k=10, config={}, **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "        spaces = Dict(\n",
    "            R=DiscreteSpace(\n",
    "                n=25, mutation_mean=0.0, mutation_std=0.01, indpb=0.01\n",
    "            ),\n",
    "            c0=MultiDiscreteSpace(\n",
    "                nvec=[1] * nb_k,\n",
    "                mutation_mean=torch.zeros((nb_k,)),\n",
    "                mutation_std=0.1 * torch.ones((nb_k,)),\n",
    "                indpb=0.1,\n",
    "            ),\n",
    "            c1=MultiDiscreteSpace(\n",
    "                nvec=[1] * nb_k,\n",
    "                mutation_mean=torch.zeros((nb_k,)),\n",
    "                mutation_std=0.1 * torch.ones((nb_k,)),\n",
    "                indpb=0.1,\n",
    "            ),\n",
    "            T=BoxSpace(\n",
    "                low=1.0,\n",
    "                high=10.0,\n",
    "                shape=(),\n",
    "                mutation_mean=0.0,\n",
    "                mutation_std=0.1,\n",
    "                indpb=0.01,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            rk=BoxSpace(\n",
    "                low=0,\n",
    "                high=1,\n",
    "                shape=(nb_k, 3),\n",
    "                mutation_mean=torch.zeros((nb_k, 3)),\n",
    "                mutation_std=0.2 * torch.ones((nb_k, 3)),\n",
    "                indpb=1,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            b=BoxSpace(\n",
    "                low=0.0,\n",
    "                high=1.0,\n",
    "                shape=(nb_k, 3),\n",
    "                mutation_mean=torch.zeros((nb_k, 3)),\n",
    "                mutation_std=0.2 * torch.ones((nb_k, 3)),\n",
    "                indpb=1,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            w=BoxSpace(\n",
    "                low=0.01,\n",
    "                high=0.5,\n",
    "                shape=(nb_k, 3),\n",
    "                mutation_mean=torch.zeros((nb_k, 3)),\n",
    "                mutation_std=0.2 * torch.ones((nb_k, 3)),\n",
    "                indpb=1,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            m=BoxSpace(\n",
    "                low=0.05,\n",
    "                high=0.5,\n",
    "                shape=(nb_k,),\n",
    "                mutation_mean=torch.zeros((nb_k,)),\n",
    "                mutation_std=0.2 * torch.ones((nb_k,)),\n",
    "                indpb=1,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            s=BoxSpace(\n",
    "                low=0.001,\n",
    "                high=0.18,\n",
    "                shape=(nb_k,),\n",
    "                mutation_mean=torch.zeros((nb_k,)),\n",
    "                mutation_std=0.01 ** torch.ones((nb_k,)),\n",
    "                indpb=0.1,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            h=BoxSpace(\n",
    "                low=0,\n",
    "                high=1.0,\n",
    "                shape=(nb_k,),\n",
    "                mutation_mean=torch.zeros((nb_k,)),\n",
    "                mutation_std=0.2 * torch.ones((nb_k,)),\n",
    "                indpb=0.1,\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            r=BoxSpace(\n",
    "                low=0.2,\n",
    "                high=1.0,\n",
    "                shape=(nb_k,),\n",
    "                mutation_mean=torch.zeros((nb_k,)),\n",
    "                mutation_std=0.2 * torch.ones((nb_k,)),\n",
    "                indpb=1,\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            # kn = DiscreteSpace(n=4, mutation_mean=0.0, mutation_std=0.1, indpb=1.0),\n",
    "            # gn = DiscreteSpace(n=3, mutation_mean=0.0, mutation_std=0.1, indpb=1.0),\n",
    "        )\n",
    "\n",
    "        DictSpace.__init__(self, spaces=spaces)\n",
    "\n",
    "    def mutate(self, x):\n",
    "        mask = (x[\"s\"] > 0.04).float() * (\n",
    "            torch.rand(x[\"s\"].shape[0]) < 0.25\n",
    "        ).float().to(x[\"s\"].device)\n",
    "        param = []\n",
    "        for k, space in self.spaces.items():\n",
    "            if k == \"R\" or k == \"c0\" or k == \"c1\" or k == \"T\":\n",
    "                param.append((k, space.mutate(x[k])))\n",
    "            elif k == \"rk\" or k == \"w\" or k == \"b\":\n",
    "                param.append((k, space.mutate(x[k], mask.unsqueeze(-1))))\n",
    "            else:\n",
    "                param.append((k, space.mutate(x[k], mask)))\n",
    "\n",
    "        return Dict(param)\n",
    "\n",
    "\n",
    "\"\"\" =============================================================================================\n",
    "Lenia Main\n",
    "============================================================================================= \"\"\"\n",
    "\n",
    "\n",
    "def bell(x, m, s):\n",
    "    return torch.exp(-(((x - m) / s) ** 2) / 2)\n",
    "\n",
    "\n",
    "# Lenia family of functions for the kernel K and for the growth mapping g\n",
    "kernel_core = {\n",
    "    0: lambda u: (4 * u * (1 - u)) ** 4,  # polynomial (quad4)\n",
    "    1: lambda u: torch.exp(\n",
    "        4 - 1 / (u * (1 - u))\n",
    "    ),  # exponential / gaussian bump (bump4)\n",
    "    2: lambda u, q=1 / 4: (u >= q).float()\n",
    "    * (u <= 1 - q).float(),  # step (stpz1/4)\n",
    "    3: lambda u, q=1 / 4: (u >= q).float() * (u <= 1 - q).float()\n",
    "    + (u < q).float() * 0.5,  # staircase (life)\n",
    "    4: lambda u: torch.exp(-((u - 0.5) ** 2) / 0.2),\n",
    "    8: lambda u: (torch.sin(10 * u) + 1) / 2,\n",
    "    9: lambda u: (a * torch.sin((u.unsqueeze(-1) * 5 * b + c) * np.pi)).sum(-1)\n",
    "    / (2 * a.sum())\n",
    "    + 1 / 2,\n",
    "}\n",
    "field_func = {\n",
    "    0: lambda n, m, s: torch.max(\n",
    "        torch.zeros_like(n), 1 - (n - m) ** 2 / (9 * s**2)\n",
    "    )\n",
    "    ** 4\n",
    "    * 2\n",
    "    - 1,  # polynomial (quad4)\n",
    "    1: lambda n, m, s: torch.exp(-((n - m) ** 2) / (2 * s**2) - 1e-3) * 2\n",
    "    - 1,  # exponential / gaussian (gaus)\n",
    "    2: lambda n, m, s: (torch.abs(n - m) <= s).float() * 2 - 1,  # step (stpz)\n",
    "    3: lambda n, m, s: -torch.clamp(n - m, 0, 1) * s,  # food eating kernl\n",
    "}\n",
    "\n",
    "# ker_c =lambda r,a,b,c :(a*torch.sin((r.unsqueeze(-1)*5*b+c)*np.pi)).sum(-1)/(2*a.sum())+1/2\n",
    "def ker_c(x, r, w, b):\n",
    "    return (b * torch.exp(-(((x.unsqueeze(-1) - r) / w) ** 2) / 2)).sum(-1)\n",
    "\n",
    "\n",
    "class Dummy_init_mod(torch.nn.Module):\n",
    "    def __init__(self, init):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.register_parameter(\"init\", torch.nn.Parameter(init))\n",
    "\n",
    "\n",
    "# Lenia Step FFT version (faster)\n",
    "class LeniaStepFFTC(torch.nn.Module):\n",
    "    \"\"\"Module pytorch that computes one Lenia Step with the fft version\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        C,\n",
    "        R,\n",
    "        T,\n",
    "        c0,\n",
    "        c1,\n",
    "        r,\n",
    "        rk,\n",
    "        b,\n",
    "        w,\n",
    "        h,\n",
    "        m,\n",
    "        s,\n",
    "        gn,\n",
    "        is_soft_clip=False,\n",
    "        SX=256,\n",
    "        SY=256,\n",
    "        speed_x=0,\n",
    "        speed_y=0,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        torch.nn.Module.__init__(self)\n",
    "\n",
    "        self.register_buffer(\"R\", R)\n",
    "        self.register_buffer(\"T\", T)\n",
    "        self.register_buffer(\"c0\", c0)\n",
    "        self.register_buffer(\"c1\", c1)\n",
    "        # self.register_buffer('r', r)\n",
    "        self.register_parameter(\"r\", torch.nn.Parameter(r))\n",
    "        self.register_parameter(\"rk\", torch.nn.Parameter(rk))\n",
    "        self.register_parameter(\"b\", torch.nn.Parameter(b))\n",
    "        self.register_parameter(\"w\", torch.nn.Parameter(w))\n",
    "        self.register_parameter(\"h\", torch.nn.Parameter(h))\n",
    "        self.register_parameter(\"m\", torch.nn.Parameter(m))\n",
    "        self.register_parameter(\"s\", torch.nn.Parameter(s))\n",
    "        self.speed_x = speed_x\n",
    "        self.speed_y = speed_y\n",
    "\n",
    "        self.gn = 1\n",
    "        self.nb_k = c0.shape[0]\n",
    "\n",
    "        self.SX = SX\n",
    "        self.SY = SY\n",
    "\n",
    "        self.is_soft_clip = is_soft_clip\n",
    "        self.C = C\n",
    "\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        self.kernels = torch.zeros((self.nb_k, self.SX, self.SY, 2)).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        self.compute_kernel()\n",
    "        self.compute_kernel_env()\n",
    "\n",
    "    def compute_kernel_env(self):\n",
    "        \"\"\"computes the kernel and the kernel FFT of the environnement from the parameters\"\"\"\n",
    "        x = torch.arange(self.SX).to(self.device)\n",
    "        y = torch.arange(self.SY).to(self.device)\n",
    "        xx = x.view(-1, 1).repeat(1, self.SY)\n",
    "        yy = y.repeat(self.SX, 1)\n",
    "        X = (xx - int(self.SX / 2)).float()\n",
    "        Y = (yy - int(self.SY / 2)).float()\n",
    "        D = torch.sqrt(X**2 + Y**2) / (4)\n",
    "        kernel = torch.sigmoid(-(D - 1) * 10) * ker_c(\n",
    "            D,\n",
    "            torch.tensor(np.array([0, 0, 0])).to(self.device),\n",
    "            torch.tensor(np.array([0.5, 0.1, 0.1])).to(self.device),\n",
    "            torch.tensor(np.array([1, 0, 0])).to(self.device),\n",
    "        )\n",
    "        kernel_sum = torch.sum(kernel)\n",
    "        kernel_norm = kernel / kernel_sum\n",
    "        # kernel_FFT = torch.rfft(kernel_norm, signal_ndim=2, onesided=False).to(self.device)\n",
    "        kernel_FFT = torch.fft.rfftn(kernel_norm, dim=(0, 1)).to(self.device)\n",
    "\n",
    "        self.kernel_wall = kernel_FFT\n",
    "\n",
    "    def compute_kernel(self):\n",
    "        \"\"\"computes the kernel and the kernel FFT of the learnable channels from the parameters\"\"\"\n",
    "        x = torch.arange(self.SX).to(self.device)\n",
    "        y = torch.arange(self.SY).to(self.device)\n",
    "        xx = x.view(-1, 1).repeat(1, self.SY)\n",
    "        yy = y.repeat(self.SX, 1)\n",
    "        X = (xx - int(self.SX / 2)).float()\n",
    "        Y = (yy - int(self.SY / 2)).float()\n",
    "        self.kernels = torch.zeros((self.nb_k, self.SX, self.SY // 2 + 1)).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        for i in range(self.nb_k):\n",
    "            # distance to center in normalized space\n",
    "            D = torch.sqrt(X**2 + Y**2) / ((self.R + 15) * self.r[i])\n",
    "\n",
    "            kernel = torch.sigmoid(-(D - 1) * 10) * ker_c(\n",
    "                D, self.rk[i], self.w[i], self.b[i]\n",
    "            )\n",
    "            kernel_sum = torch.sum(kernel)\n",
    "\n",
    "            # normalization of the kernel\n",
    "            kernel_norm = kernel / kernel_sum\n",
    "            # plt.imshow(kernel_norm[0,0].detach().cpu()*100)\n",
    "            # plt.show()\n",
    "\n",
    "            # fft of the kernel\n",
    "            # kernel_FFT = torch.rfft(kernel_norm, signal_ndim=2, onesided=False).to(self.device)\n",
    "            kernel_FFT = torch.fft.rfftn(kernel_norm, dim=(0, 1)).to(\n",
    "                self.device\n",
    "            )\n",
    "\n",
    "            self.kernels[i] = kernel_FFT\n",
    "\n",
    "    def forward(self, input):\n",
    "        input[:, :, :, 1] = torch.roll(\n",
    "            input[:, :, :, 1], [self.speed_y, self.speed_x], [1, 2]\n",
    "        )\n",
    "        self.D = torch.zeros(input.shape).to(self.device)\n",
    "        self.Dn = torch.zeros(self.C)\n",
    "\n",
    "        # world_FFT = [torch.rfft(input[:,:,:,i], signal_ndim=2, onesided=False) for i in range(self.C)]\n",
    "        world_FFT = [\n",
    "            torch.fft.rfftn(input[:, :, :, i], dim=(1, 2))\n",
    "            for i in range(self.C)\n",
    "        ]\n",
    "\n",
    "        ## speed up of the update for 1 channel creature by multiplying by all the kernel FFT\n",
    "\n",
    "        # channel 0 is the learnable channel\n",
    "        world_FFT_c = world_FFT[0]\n",
    "        # multiply the FFT of the world and the kernels\n",
    "        potential_FFT = self.kernels * world_FFT_c\n",
    "        # ifft + realignself.SY//2+1\n",
    "        potential = torch.fft.irfftn(potential_FFT, dim=(1, 2))\n",
    "        potential = roll_n(potential, 2, potential.size(2) // 2)\n",
    "        potential = roll_n(potential, 1, potential.size(1) // 2)\n",
    "        # growth function\n",
    "        gfunc = field_func[min(self.gn, 3)]\n",
    "        field = gfunc(\n",
    "            potential,\n",
    "            self.m.unsqueeze(-1).unsqueeze(-1),\n",
    "            self.s.unsqueeze(-1).unsqueeze(-1),\n",
    "        )\n",
    "        # add the growth multiplied by the weight of the rule to the total growth\n",
    "        self.D[:, :, :, 0] = (self.h.unsqueeze(-1).unsqueeze(-1) * field).sum(\n",
    "            0, keepdim=True\n",
    "        )\n",
    "        self.Dn[0] = self.h.sum()\n",
    "\n",
    "        ###Base version for the case where we want the learnable creature to be  multi channel (which is not used in this notebook)\n",
    "\n",
    "        # for i in range(self.nb_k):\n",
    "        #   c0b=int((self.c0[i]))\n",
    "        #   c1b=int((self.c1[i]))\n",
    "\n",
    "        #   world_FFT_c = world_FFT[c0b]\n",
    "        #   potential_FFT = complex_mult_torch(self.kernels[i].unsqueeze(0), world_FFT_c)\n",
    "\n",
    "        #   potential = torch.irfft(potential_FFT, signal_ndim=2, onesided=False)\n",
    "        #   potential = roll_n(potential, 2, potential.size(2) // 2)\n",
    "        #   potential = roll_n(potential, 1, potential.size(1) // 2)\n",
    "\n",
    "        #   gfunc = field_func[min(self.gn, 3)]\n",
    "        #   field = gfunc(potential, self.m[i], self.s[i])\n",
    "\n",
    "        #   self.D[:,:,:,c1b]=self.D[:,:,:,c1b]+self.h[i]*field\n",
    "        #   self.Dn[c1b]=self.Dn[c1b]+self.h[i]\n",
    "\n",
    "        # apply wall\n",
    "        world_FFT_c = world_FFT[self.C - 1]\n",
    "        potential_FFT = self.kernel_wall * world_FFT_c\n",
    "        potential = torch.fft.irfftn(potential_FFT, dim=(1, 2))\n",
    "        potential = roll_n(potential, 2, potential.size(2) // 2)\n",
    "        potential = roll_n(potential, 1, potential.size(1) // 2)\n",
    "        gfunc = field_func[3]\n",
    "        field = gfunc(potential, 1e-8, 10)\n",
    "        for i in range(self.C - 1):\n",
    "            c1b = i\n",
    "            self.D[:, :, :, c1b] = self.D[:, :, :, c1b] + 1 * field\n",
    "            self.Dn[c1b] = self.Dn[c1b] + 1\n",
    "\n",
    "        ## Add the total growth to the current state\n",
    "        if not self.is_soft_clip:\n",
    "\n",
    "            output_img = torch.clamp(\n",
    "                input + (1.0 / self.T) * self.D, min=0.0, max=1.0\n",
    "            )\n",
    "            # output_img = input + (1.0 / self.T) * ((self.D/self.Dn+1)/2-input)\n",
    "\n",
    "        else:\n",
    "            output_img = torch.sigmoid(\n",
    "                (input + (1.0 / self.T) * self.D - 0.5) * 10\n",
    "            )\n",
    "            # output_img = torch.tanh(input + (1.0 / self.T) * self.D)\n",
    "\n",
    "        return output_img\n",
    "\n",
    "\n",
    "class Lenia_C(torch.nn.Module):\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        default_config.version = (\n",
    "            \"pytorch_fft\"  # \"pytorch_fft\", \"pytorch_conv2d\"\n",
    "        )\n",
    "        default_config.SX = 256\n",
    "        default_config.SY = 256\n",
    "        default_config.final_step = 40\n",
    "        default_config.C = 2\n",
    "        default_config.speed_x = 0\n",
    "        default_config.speed_y = 0\n",
    "        return default_config\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        initialization_space=None,\n",
    "        update_rule_space=None,\n",
    "        nb_k=10,\n",
    "        init_size=40,\n",
    "        config={},\n",
    "        device=torch.device(\"cpu\"),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.device = device\n",
    "        self.init_size = init_size\n",
    "        if initialization_space is not None:\n",
    "            self.initialization_space = initialization_space\n",
    "        else:\n",
    "            self.initialization_space = LeniaInitializationSpace(\n",
    "                self.init_size\n",
    "            )\n",
    "\n",
    "        if update_rule_space is not None:\n",
    "            self.update_rule_space = update_rule_space\n",
    "        else:\n",
    "            self.update_rule_space = LeniaUpdateRuleSpace(nb_k)\n",
    "\n",
    "        self.run_idx = 0\n",
    "        self.init_wall = torch.zeros((self.config.SX, self.config.SY))\n",
    "        # reset with no argument to sample random parameters\n",
    "        self.reset()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def reset(\n",
    "        self, initialization_parameters=None, update_rule_parameters=None\n",
    "    ):\n",
    "        # call the property setters\n",
    "        if initialization_parameters is not None:\n",
    "            self.initialization_parameters = initialization_parameters\n",
    "        else:\n",
    "            self.initialization_parameters = self.initialization_space.sample()\n",
    "\n",
    "        if update_rule_parameters is not None:\n",
    "            self.update_rule_parameters = update_rule_parameters\n",
    "        else:\n",
    "            policy_parameters = Dict.fromkeys([\"update_rule\"])\n",
    "            policy_parameters[\"update_rule\"] = self.update_rule_space.sample()\n",
    "            # divide h by 3 at the beginning as some unbalanced kernels can easily kill\n",
    "            policy_parameters[\"update_rule\"].h = (\n",
    "                policy_parameters[\"update_rule\"].h / 3\n",
    "            )\n",
    "            self.update_rule_parameters = policy_parameters[\"update_rule\"]\n",
    "\n",
    "        # initialize Lenia CA with update rule parameters\n",
    "        if self.config.version == \"pytorch_fft\":\n",
    "            lenia_step = LeniaStepFFTC(\n",
    "                self.config.C,\n",
    "                self.update_rule_parameters[\"R\"],\n",
    "                self.update_rule_parameters[\"T\"],\n",
    "                self.update_rule_parameters[\"c0\"],\n",
    "                self.update_rule_parameters[\"c1\"],\n",
    "                self.update_rule_parameters[\"r\"],\n",
    "                self.update_rule_parameters[\"rk\"],\n",
    "                self.update_rule_parameters[\"b\"],\n",
    "                self.update_rule_parameters[\"w\"],\n",
    "                self.update_rule_parameters[\"h\"],\n",
    "                self.update_rule_parameters[\"m\"],\n",
    "                self.update_rule_parameters[\"s\"],\n",
    "                1,\n",
    "                is_soft_clip=False,\n",
    "                SX=self.config.SX,\n",
    "                SY=self.config.SY,\n",
    "                speed_x=self.config.speed_x,\n",
    "                speed_y=self.config.speed_y,\n",
    "                device=self.device,\n",
    "            )\n",
    "        self.add_module(\"lenia_step\", lenia_step)\n",
    "\n",
    "        # initialize Lenia initial state with initialization_parameters\n",
    "        init = self.initialization_parameters[\"init\"]\n",
    "        # initialization_cppn = pytorchneat.rnn.RecurrentNetwork.create(cppn_genome, self.initialization_space.config.neat_config, device=self.device)\n",
    "        self.add_module(\"initialization\", Dummy_init_mod(init))\n",
    "\n",
    "        # push the nn.Module and the available device\n",
    "        self.to(self.device)\n",
    "        self.generate_init_state()\n",
    "\n",
    "    def random_obstacle(self, nb_obstacle=6):\n",
    "        self.init_wall = torch.zeros((self.config.SX, self.config.SY))\n",
    "\n",
    "        x = torch.arange(self.config.SX)\n",
    "        y = torch.arange(self.config.SY)\n",
    "        xx = x.view(-1, 1).repeat(1, self.config.SY)\n",
    "        yy = y.repeat(self.config.SX, 1)\n",
    "        for i in range(nb_obstacle):\n",
    "            X = (xx - int(torch.rand(1) * self.config.SX)).float()\n",
    "            Y = (yy - int(torch.rand(1) * self.config.SY / 2)).float()\n",
    "            D = torch.sqrt(X**2 + Y**2) / 10\n",
    "            mask = (D < 1).float()\n",
    "            self.init_wall = torch.clamp(self.init_wall + mask, 0, 1)\n",
    "\n",
    "    def random_obstacle_bis(self, nb_obstacle=6):\n",
    "        self.init_wall = torch.zeros((self.config.SX, self.config.SY))\n",
    "\n",
    "        x = torch.arange(self.config.SX)\n",
    "        y = torch.arange(self.config.SY)\n",
    "        xx = x.view(-1, 1).repeat(1, self.config.SY)\n",
    "        yy = y.repeat(self.config.SX, 1)\n",
    "        for i in range(nb_obstacle):\n",
    "            X = (xx - int(torch.rand(1) * self.config.SX)).float()\n",
    "            Y = (yy - int(torch.rand(1) * self.config.SY)).float()\n",
    "            D = torch.sqrt(X**2 + Y**2) / 10\n",
    "            mask = (D < 1).float()\n",
    "            self.init_wall = torch.clamp(self.init_wall + mask, 0, 1)\n",
    "        self.init_wall[95:155, 170:230] = 0\n",
    "\n",
    "    def generate_init_state(self, X=105, Y=180):\n",
    "        init_state = torch.zeros(\n",
    "            1,\n",
    "            self.config.SX,\n",
    "            self.config.SY,\n",
    "            self.config.C,\n",
    "            dtype=torch.float64,\n",
    "        )\n",
    "        init_state[\n",
    "            0, X : X + self.init_size, Y : Y + self.init_size, 0\n",
    "        ] = self.initialization.init\n",
    "        if self.config.C > 1:\n",
    "            init_state[0, :, :, 1] = self.init_wall\n",
    "        self.state = init_state.to(self.device)\n",
    "        self.step_idx = 0\n",
    "\n",
    "    def update_initialization_parameters(self):\n",
    "        new_initialization_parameters = deepcopy(\n",
    "            self.initialization_parameters\n",
    "        )\n",
    "        new_initialization_parameters[\"init\"] = self.initialization.init.data\n",
    "        if not self.initialization_space.contains(\n",
    "            new_initialization_parameters\n",
    "        ):\n",
    "            new_initialization_parameters = self.initialization_space.clamp(\n",
    "                new_initialization_parameters\n",
    "            )\n",
    "            warnings.warn(\n",
    "                \"provided parameters are not in the space range and are therefore clamped\"\n",
    "            )\n",
    "        self.initialization_parameters = new_initialization_parameters\n",
    "\n",
    "    def update_update_rule_parameters(self):\n",
    "        new_update_rule_parameters = deepcopy(self.update_rule_parameters)\n",
    "        # gather the parameter from the lenia step (which may have been optimized)\n",
    "        new_update_rule_parameters[\"m\"] = self.lenia_step.m.data\n",
    "        new_update_rule_parameters[\"s\"] = self.lenia_step.s.data\n",
    "        new_update_rule_parameters[\"r\"] = self.lenia_step.r.data\n",
    "        new_update_rule_parameters[\"rk\"] = self.lenia_step.rk.data\n",
    "        new_update_rule_parameters[\"b\"] = self.lenia_step.b.data\n",
    "        new_update_rule_parameters[\"w\"] = self.lenia_step.w.data\n",
    "        new_update_rule_parameters[\"h\"] = self.lenia_step.h.data\n",
    "        if not self.update_rule_space.contains(new_update_rule_parameters):\n",
    "            new_update_rule_parameters = self.update_rule_space.clamp(\n",
    "                new_update_rule_parameters\n",
    "            )\n",
    "            warnings.warn(\n",
    "                \"provided parameters are not in the space range and are therefore clamped\"\n",
    "            )\n",
    "        self.update_rule_parameters = new_update_rule_parameters\n",
    "\n",
    "    def step(self, intervention_parameters=None):\n",
    "        self.state = self.lenia_step(self.state)\n",
    "        self.step_idx += 1\n",
    "        return self.state\n",
    "\n",
    "    def forward(self):\n",
    "        state = self.step(None)\n",
    "        return state\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"run lenia for the number of step specified in the config.\n",
    "        Returns the observations containing the state at each timestep\"\"\"\n",
    "        # clip parameters just in case\n",
    "        if not self.initialization_space[\"init\"].contains(\n",
    "            self.initialization.init.data\n",
    "        ):\n",
    "            self.initialization.init.data = self.initialization_space[\n",
    "                \"init\"\n",
    "            ].clamp(self.initialization.init.data)\n",
    "        if not self.update_rule_space[\"r\"].contains(self.lenia_step.r.data):\n",
    "            self.lenia_step.r.data = self.update_rule_space[\"r\"].clamp(\n",
    "                self.lenia_step.r.data\n",
    "            )\n",
    "        if not self.update_rule_space[\"rk\"].contains(self.lenia_step.rk.data):\n",
    "            self.lenia_step.rk.data = self.update_rule_space[\"rk\"].clamp(\n",
    "                self.lenia_step.rk.data\n",
    "            )\n",
    "        if not self.update_rule_space[\"b\"].contains(self.lenia_step.b.data):\n",
    "            self.lenia_step.b.data = self.update_rule_space[\"b\"].clamp(\n",
    "                self.lenia_step.b.data\n",
    "            )\n",
    "        if not self.update_rule_space[\"w\"].contains(self.lenia_step.w.data):\n",
    "            self.lenia_step.w.data = self.update_rule_space[\"w\"].clamp(\n",
    "                self.lenia_step.w.data\n",
    "            )\n",
    "        if not self.update_rule_space[\"h\"].contains(self.lenia_step.h.data):\n",
    "            self.lenia_step.h.data = self.update_rule_space[\"h\"].clamp(\n",
    "                self.lenia_step.h.data\n",
    "            )\n",
    "        if not self.update_rule_space[\"m\"].contains(self.lenia_step.m.data):\n",
    "            self.lenia_step.m.data = self.update_rule_space[\"m\"].clamp(\n",
    "                self.lenia_step.m.data\n",
    "            )\n",
    "        if not self.update_rule_space[\"s\"].contains(self.lenia_step.s.data):\n",
    "            self.lenia_step.s.data = self.update_rule_space[\"s\"].clamp(\n",
    "                self.lenia_step.s.data\n",
    "            )\n",
    "        # self.generate_init_state()\n",
    "        observations = Dict()\n",
    "        observations.timepoints = list(range(self.config.final_step))\n",
    "        observations.states = torch.empty(\n",
    "            (\n",
    "                self.config.final_step,\n",
    "                self.config.SX,\n",
    "                self.config.SY,\n",
    "                self.config.C,\n",
    "            )\n",
    "        )\n",
    "        observations.states[0] = self.state\n",
    "        for step_idx in range(1, self.config.final_step):\n",
    "            cur_observation = self.step(None)\n",
    "            observations.states[step_idx] = cur_observation[0, :, :, :]\n",
    "\n",
    "        return observations\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"\n",
    "        Saves the system object using torch.save function in pickle format\n",
    "        Can be used if the system state's change over exploration and we want to dump it\n",
    "        \"\"\"\n",
    "        torch.save(self, filepath)\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = Lenia_C(nb_k=5)\n",
    "system.config.final_step = 200\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(4):\n",
    "        # the method system.reset() sets random parameters for Lenia update rule, unless update_rule_parameters are passed as argument\n",
    "        system.reset()\n",
    "        # the method system.generate_init_state() allows to generate a random intialization square in all channels (but you can replace it by setting yourself the system.state)\n",
    "        system.random_obstacle(0)\n",
    "        system.generate_init_state()\n",
    "        # the method system.run() launches a rollout in Lenia\n",
    "        observations = system.run()\n",
    "\n",
    "        with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "            for timestep in range(observations[\"states\"].shape[0]):\n",
    "\n",
    "                rgb_im = (\n",
    "                    observations.states[timestep, :, :, 0]\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "                vid.add(rgb_im)\n",
    "            vid.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 examples of discovered creatures (1 channel and 10 rules)\n",
    "\n",
    "!wget  'https://osf.io/tqxhu/download' -O 'crea1.pickle'\n",
    "!wget  'https://osf.io/tqfwk/download' -O 'crea2.pickle'\n",
    "!wget  'https://osf.io/ba536/download' -O 'crea3.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@title Main\n",
    "# SY =  256#@param {type:\"integer\"}\n",
    "# SX =  256#@param {type:\"integer\"}\n",
    "# # timesteps =  200#@param {type:\"integer\"}\n",
    "# mode = \"draw\" #@param [\"draw\", \"random\"]\n",
    "# modeb = \"none\" #@param [\"growth\", \"sum\", \"none\", \"both\"]\n",
    "# borders = False #@param {type:\"boolean\"}\n",
    "# creature= \"crea2\"  #@param [\"crea1\",\"crea2\",\"crea3\"]\n",
    "# device = \"cpu\"\n",
    "# main(SX,SY,mode,borders,[0,1,2,3,4,5,6,7,8,9],creaFile=creature+\".pickle\",modeb=modeb,zoom=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.cm as cm\n",
    "# import cv2\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import time\n",
    "# from IPython.display import Video, display\n",
    "\n",
    "# # NOTE: The following classes/functions must be available:\n",
    "# # - Lenia_C (with Lenia_C.default_config())\n",
    "# # - LeniaInitializationSpace\n",
    "# # - VideoWriter (a context manager for writing videos)\n",
    "\n",
    "# def main(SX, SY, mode='random', borders=False, list_kernels=range(10),\n",
    "#          creaFile=\"crea1.pickle\", modeb='none', zoom=1):\n",
    "#     # Configure the simulation\n",
    "#     lenia_config = Lenia_C.default_config()\n",
    "#     lenia_config.SX = SX\n",
    "#     lenia_config.SY = SY\n",
    "#     lenia_config.final_step = 200  # number of timesteps\n",
    "#     lenia_config.version = 'pytorch_fft'\n",
    "#     lenia_config.nb_kernels = len(list_kernels)\n",
    "\n",
    "#     # Create the initialization space and system\n",
    "#     initialization_space_config = {}  # use a plain dict for simplicity\n",
    "#     initialization_space = LeniaInitializationSpace(config=initialization_space_config)\n",
    "#     system = Lenia_C(initialization_space=initialization_space, config=lenia_config, device=device)\n",
    "\n",
    "#     # Load initial configuration from file\n",
    "#     a = torch.load(creaFile, map_location=torch.device(device))\n",
    "#     policy_parameters = {}\n",
    "#     policy_parameters['initialization'] = a['policy_parameters']['initialization']\n",
    "#     policy_parameters['update_rule'] = a['policy_parameters']['update_rule']\n",
    "#     policy_parameters['update_rule']['R'] = (policy_parameters['update_rule']['R'] + 15) * zoom - 15\n",
    "\n",
    "#     # For each update rule parameter (except R and T), select the desired kernels and move them to device\n",
    "#     for k in policy_parameters['update_rule'].keys():\n",
    "#         if k not in ['R', 'T']:\n",
    "#             policy_parameters['update_rule'][k] = policy_parameters['update_rule'][k][list_kernels]\n",
    "#         policy_parameters['update_rule'][k] = policy_parameters['update_rule'][k].to(device)\n",
    "\n",
    "#     # Prepare the initial state image from the initialization parameters\n",
    "#     init_s = policy_parameters['initialization'].init.cpu().numpy().astype(np.float32)\n",
    "#     width = int(init_s.shape[1] * zoom)\n",
    "#     height = int(init_s.shape[0] * zoom)\n",
    "#     # Resize image using OpenCV (note: cv2.resize expects (width, height))\n",
    "#     init_f = cv2.resize(init_s, (width, height))\n",
    "#     init_f = torch.tensor(init_f).to(device)\n",
    "\n",
    "#     # Reset the system with the loaded parameters\n",
    "#     system.reset(initialization_parameters=policy_parameters['initialization'],\n",
    "#                  update_rule_parameters=policy_parameters['update_rule'])\n",
    "\n",
    "#     # In random mode, add obstacles automatically (no interactive drawing)\n",
    "#     if mode == 'random':\n",
    "#         # nb_obstacle = 100   # for example\n",
    "#         # radius_obstacle = 10\n",
    "#         system.random_obstacle()\n",
    "\n",
    "#     # Optionally add border walls\n",
    "#     if borders:\n",
    "#         system.init_wall[:, :4] = 1\n",
    "#         system.init_wall[:, -4:] = 1\n",
    "#         system.init_wall[-4:, :] = 1\n",
    "#         system.init_wall[:4, :] = 1\n",
    "\n",
    "\n",
    "#     # if(np.all(img[:,:,0]<240)):\n",
    "#     #     print(\"you didn't put the creature, creature put automatically in the bottom right corner\")\n",
    "#     # else:\n",
    "#     system.init_loca=[]\n",
    "\n",
    "#     for i in range(1,SX-40):\n",
    "#         for j in range(1,SY-40):\n",
    "#             # if(img[i,j,0]>240 and img[i-1,j,0]<240 and img[i,j-1,0]<240 and img[i+1,j,0]>240 and img[i,j+1,0]>240):\n",
    "#             system.init_loca.append((i,j))\n",
    "\n",
    "#     print('Running Lenia simulation...')\n",
    "#     t0 = time.time()\n",
    "#     with torch.no_grad():\n",
    "#         system.generate_init_state()\n",
    "#         # Insert the initial configuration image into the simulation state\n",
    "#         for loca in system.init_loca:\n",
    "#             x, y = loca\n",
    "#             system.state[0, x:x+init_f.shape[0], y:y+init_f.shape[1], 0] = init_f\n",
    "#         observations = system.run()\n",
    "#     sim_time = time.time() - t0\n",
    "#     print(f\"Simulation completed in {sim_time:.2f} seconds.\")\n",
    "\n",
    "#     # Create an animation video from the simulation observations.\n",
    "#     # Here we use only the first channel of the state and apply a 'jet' colormap.\n",
    "#     cmap = cm.get_cmap('jet')\n",
    "#     video_filename = \"out.mp4\"\n",
    "#     fps = 30.0\n",
    "\n",
    "#     with VideoWriter(video_filename, fps) as vid:\n",
    "#         for t in range(observations[\"states\"].shape[0]):\n",
    "#             # Extract the first channel of the state at timestep t\n",
    "#             state = observations[\"states\"][t, :, :, 0].detach().cpu().numpy()\n",
    "#             # Normalize the state to [0, 1]\n",
    "#             norm_state = (state - state.min()) / (state.max() - state.min() + 1e-8)\n",
    "#             # Apply colormap and convert to an 8-bit RGB image\n",
    "#             rgb_frame = (cmap(norm_state)[:, :, :3] * 255).astype(np.uint8)\n",
    "#             vid.add(rgb_frame)\n",
    "\n",
    "#     # Display the video inline in the notebook\n",
    "#     print(observations[\"states\"])\n",
    "#     display(Video(video_filename, embed=True))\n",
    "\n",
    "# # Run the simulation with chosen parameters\n",
    "# SX = 256\n",
    "# SY = 256\n",
    "# mode = \"random\"     # non-interactive mode\n",
    "# modeb = \"none\"\n",
    "# borders = False\n",
    "# creature = \"crea2\"   # filename (without extension) for the initial configuration\n",
    "# main(SX, SY, mode, borders, list(range(10)), creaFile=creature + \".pickle\", modeb=modeb, zoom=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from IPython.display import Image as IPImage\n",
    "from IPython.display import display\n",
    "import imageio\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "\n",
    "# NOTE: The following classes/functions must be available:\n",
    "# - Lenia_C (with Lenia_C.default_config())\n",
    "# - LeniaInitializationSpace\n",
    "\n",
    "# Ensure the device is defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def main(\n",
    "    SX,\n",
    "    SY,\n",
    "    mode=\"random\",\n",
    "    borders=False,\n",
    "    list_kernels=range(10),\n",
    "    creaFile=\"crea1.pickle\",\n",
    "    modeb=\"none\",\n",
    "    zoom=1,\n",
    "):\n",
    "    # Configure the simulation\n",
    "    lenia_config = Lenia_C.default_config()\n",
    "    lenia_config.SX = SX\n",
    "    lenia_config.SY = SY\n",
    "    lenia_config.final_step = 200  # number of timesteps\n",
    "    lenia_config.version = \"pytorch_fft\"\n",
    "    lenia_config.nb_kernels = len(list_kernels)\n",
    "\n",
    "    # Create the initialization space and system\n",
    "    initialization_space_config = {}  # use a plain dict for simplicity\n",
    "    initialization_space = LeniaInitializationSpace(\n",
    "        config=initialization_space_config\n",
    "    )\n",
    "    system = Lenia_C(\n",
    "        initialization_space=initialization_space,\n",
    "        config=lenia_config,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Load initial configuration from file\n",
    "    a = torch.load(creaFile, map_location=device)\n",
    "    policy_parameters = {}\n",
    "    policy_parameters[\"initialization\"] = a[\"policy_parameters\"][\n",
    "        \"initialization\"\n",
    "    ]\n",
    "    policy_parameters[\"update_rule\"] = a[\"policy_parameters\"][\"update_rule\"]\n",
    "    policy_parameters[\"update_rule\"][\"R\"] = (\n",
    "        policy_parameters[\"update_rule\"][\"R\"] + 15\n",
    "    ) * zoom - 15\n",
    "\n",
    "    # For each update rule parameter (except R and T), select the desired kernels and move them to device\n",
    "    for k in policy_parameters[\"update_rule\"].keys():\n",
    "        if k not in [\"R\", \"T\"]:\n",
    "            policy_parameters[\"update_rule\"][k] = policy_parameters[\n",
    "                \"update_rule\"\n",
    "            ][k][list_kernels]\n",
    "        policy_parameters[\"update_rule\"][k] = policy_parameters[\"update_rule\"][\n",
    "            k\n",
    "        ].to(device)\n",
    "\n",
    "    # Prepare the initial state image from the initialization parameters\n",
    "    init_s = (\n",
    "        policy_parameters[\"initialization\"]\n",
    "        .init.cpu()\n",
    "        .numpy()\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "    width = int(init_s.shape[1] * zoom)\n",
    "    height = int(init_s.shape[0] * zoom)\n",
    "    # Resize image using OpenCV (note: cv2.resize expects (width, height))\n",
    "    init_f = cv2.resize(init_s, (width, height))\n",
    "    init_f = torch.tensor(init_f).to(device)\n",
    "\n",
    "    # Reset the system with the loaded parameters\n",
    "    system.reset(\n",
    "        initialization_parameters=policy_parameters[\"initialization\"],\n",
    "        update_rule_parameters=policy_parameters[\"update_rule\"],\n",
    "    )\n",
    "\n",
    "    # In random mode, add obstacles automatically (no interactive drawing)\n",
    "    if mode == \"random\":\n",
    "        system.random_obstacle()\n",
    "\n",
    "    # Optionally add border walls\n",
    "    if borders:\n",
    "        system.init_wall[:, :4] = 1\n",
    "        system.init_wall[:, -4:] = 1\n",
    "        system.init_wall[-4:, :] = 1\n",
    "        system.init_wall[:4, :] = 1\n",
    "\n",
    "    system.init_loca = []\n",
    "    for i in range(1, SX - 40):\n",
    "        for j in range(1, SY - 40):\n",
    "            system.init_loca.append((i, j))\n",
    "\n",
    "    print(\"Running Lenia simulation...\")\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        system.generate_init_state()\n",
    "        # Insert the initial configuration image into the simulation state\n",
    "        for loca in system.init_loca:\n",
    "            x, y = loca\n",
    "            system.state[\n",
    "                0, x : x + init_f.shape[0], y : y + init_f.shape[1], 0\n",
    "            ] = init_f\n",
    "        observations = system.run()\n",
    "    sim_time = time.time() - t0\n",
    "    print(f\"Simulation completed in {sim_time:.2f} seconds.\")\n",
    "\n",
    "    # Create a GIF from the simulation observations.\n",
    "    cmap = cm.get_cmap(\"jet\")\n",
    "    fps = 30.0  # Frames per second for the GIF\n",
    "    frames = []\n",
    "    for t in range(observations[\"states\"].shape[0]):\n",
    "        # Extract the first channel of the state at timestep t\n",
    "        state = observations[\"states\"][t, :, :, 0].detach().cpu().numpy()\n",
    "        # Normalize the state to [0, 1]\n",
    "        norm_state = (state - state.min()) / (state.max() - state.min() + 1e-8)\n",
    "        # Apply colormap and convert to an 8-bit RGB image\n",
    "        rgb_frame = (cmap(norm_state)[:, :, :3] * 255).astype(np.uint8)\n",
    "        frames.append(rgb_frame)\n",
    "\n",
    "    gif_filename = \"out.gif\"\n",
    "    imageio.mimsave(gif_filename, frames, fps=fps)\n",
    "\n",
    "    # Display the GIF inline in the notebook\n",
    "    display(IPImage(filename=gif_filename))\n",
    "\n",
    "\n",
    "# Run the simulation with chosen parameters\n",
    "SX = 256\n",
    "SY = 256\n",
    "mode = \"random\"  # non-interactive mode\n",
    "modeb = \"none\"\n",
    "borders = False\n",
    "creature = (\n",
    "    \"crea2\"  # filename (without extension) for the initial configuration\n",
    ")\n",
    "main(\n",
    "    SX,\n",
    "    SY,\n",
    "    mode,\n",
    "    borders,\n",
    "    list(range(10)),\n",
    "    creaFile=creature + \".pickle\",\n",
    "    modeb=modeb,\n",
    "    zoom=1,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
